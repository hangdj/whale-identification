{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task and Approach Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are numerous prediction classes, the problem is better modeled as a verification or re-identification task. Moreover, the problem of whale identification is isomorphic to the task of face recognition, which is well researched and applied in huge datasets (e.g Facebook, Google). Therefore, we'll base our approach on one such successful methodology: Google FaceNet, as described in [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach will deviate from FaceNet in a few key areas:\n",
    "- We'll utilize transfer learning from a network pre-trained on ImageNet for high level feature extraction.\n",
    "- We'll form our triplets offline over the whole as well.\n",
    "- We'll perform offline feature extraction, as opposed to online batch-local feature extraction as described in the FaceNet paper. \n",
    "- We'll select hard-negatives offline using the extracted intermediate features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.applications.nasnet import NASNetMobile,preprocess_input\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Input, concatenate\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet training loss\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    length = y_pred.shape.as_list()[-1]\n",
    "    anchor = y_pred[:,:128]\n",
    "    positive = y_pred[:,128:256]\n",
    "    negative = y_pred[:,256:]\n",
    "    # distance between the anchor and the positive,negative\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained feature extraction model\n",
    "transfer_model = NASNetMobile(\n",
    "    weights='imagenet', \n",
    "    include_top=False,\n",
    "    input_shape=(140,210,3),\n",
    "    pooling='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze pre-trained model\n",
    "for layer in transfer_model.layers:\n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for more information aboud NASNetMobile\n",
    "# transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = transfer_model.output\n",
    "x = Dense(512)(x)\n",
    "x = Dense(256)(x)\n",
    "x = Dense(128,kernel_regularizer=l2(0.01))(x)\n",
    "base_model = Model(inputs=transfer_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model architecture overview\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_model(base_model):\n",
    "    anchor_input = Input((140,210,3), name='anchor_input')\n",
    "    positive_input = Input((140,210,3), name='positive_input')\n",
    "    negative_input = Input((140,210,3), name='negative_input')\n",
    "    # Shared embedding layer for positive and negative items\n",
    "    encoded_anchor = base_model(anchor_input)\n",
    "    encoded_positive = base_model(positive_input)\n",
    "    encoded_negative = base_model(negative_input)\n",
    "    # triplet model output - ignored\n",
    "    merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative],axis=-1)\n",
    "    model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "    model.compile(loss=triplet_loss, optimizer=Adam(lr=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18701, 3, 140, 210, 3)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# triplet model architecture overview\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll initially train on randomly selected triplets until the network performs well enough to be utilized for further training triplets generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('./data/train_clean.csv')\n",
    "labels.Image = './data/train_clean/'+labels.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4774846"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The image triplets will use ~5.5GB of main memory. \n",
    "# Therefore, we can just load everything into RAM without utilizing a generator.\n",
    "len(labels)*3*140*210*3/10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((20701,3,140,210,3),dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load randomly sampled triplets\n",
    "for lbl in labels.itertuples():\n",
    "    X[lbl.Index,0] = preprocess_input(cv2.imread(lbl.Image))\n",
    "    X[lbl.Index,1] = preprocess_input(\n",
    "        cv2.imread(\n",
    "        labels.Image[(labels.Id==lbl.Id)&(labels.Image!=lbl.Image)].sample().iloc[0]))\n",
    "    X[lbl.Index,2] = preprocess_input(\n",
    "        cv2.imread(labels.Image[labels.Id != lbl.Id].sample().iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train = X[1000:]\n",
    "X_test = X[:1000]\n",
    "y_train = np.empty((X_train.shape[0],128)) # dummy\n",
    "y_test = np.empty((X_test.shape[0],128)) # dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15701 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "15701/15701 [==============================] - 18540s 1s/step - loss: 168.7966 - val_loss: 11465.4871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x451af6710>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train[:,0],X_train[:,1],X_train[:,2]],y=y_train,\n",
    "          validation_data=([X_test[:,0],X_test[:,1],X_test[:,2]],y_test),\n",
    "          batch_size=512, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save(filepath='./model.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model = load_model(filepath='./model.hdf5')\n",
    "# trained_model.compile(optimizer=Adam(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features and add to labeled data\n",
    "imgs = np.array([preprocess_input(cv2.imread(lbl.Image)) for lbl in labels.itertuples()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = trained_model.predict(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['Features'] = features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = labels.Id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select representative features for each class\n",
    "cls_repr = {}\n",
    "for Id in unique_ids:\n",
    "    ftrs = np.array([np.array(f) for f in labels[labels.Id == Id].Features])\n",
    "    centroid = np.mean(ftrs,axis=0)\n",
    "    cls_repr[Id] = centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean distance\n",
    "def distance(vec1,vec2):\n",
    "    return np.sqrt(np.sum(np.square(vec1-vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top five predictions\n",
    "def top_five(img):\n",
    "    ftrs = trained_model.predict(img[None,...])[0]\n",
    "    return sorted([(distance(cls_repr[Id],ftrs),Id) for Id in unique_ids])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth:\n",
      "w_f48451c\n",
      "Top five predictions:\n",
      "(16.185738940751019, 'w_f48451c')\n",
      "(16.548555263056986, 'w_8d76b75')\n",
      "(17.247622089332403, 'w_1baf8df')\n",
      "(17.456435307224197, 'w_0d4a14b')\n",
      "(17.609687916312609, 'w_9438119')\n"
     ]
    }
   ],
   "source": [
    "# demo single image identification\n",
    "preds = top_five(preprocess_input(cv2.imread(labels.Image[0])))\n",
    "print('Truth:',labels.Id[0],'Top five predictions:',*preds, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_five(num_samples):\n",
    "    map5 = 0.0\n",
    "    for lbl in labels.sample(n=num_samples).itertuples():\n",
    "        preds = top_five(preprocess_input(cv2.imread(lbl.Image)))\n",
    "        map5 += sum([(p[1]==lbl.Id)/i for i,p in zip(range(1,6),preds)])\n",
    "    return map5/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean average pericion of top five predictions per each sample:\n",
      "0.46875\n"
     ]
    }
   ],
   "source": [
    "print('Mean average pericion of top five predictions per each sample:')\n",
    "print(map_five(num_samples=64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Grained Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute anchors, hard-egatives, hard-Positives and forms triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_triplets(num_samples):\n",
    "    anchors, positives, negatives = [],[],[]\n",
    "    for lbl in labels.sample(n=num_samples).itertuples():\n",
    "        neg_lbls = labels[labels.Id != lbl.Id].sample(n=1024).itertuples()\n",
    "        pos_lbls = labels[(labels.Id == lbl.Id) & (labels.Image != lbl.Image)].itertuples()\n",
    "        hard_neg = min([(distance(cls_repr[n.Id],lbl.Features),n.Image) for n in neg_lbls])[1]\n",
    "        hard_pos = max([(distance(cls_repr[n.Id],lbl.Features),n.Image) for n in pos_lbls])[1]\n",
    "        anchors.append(lbl.Image)\n",
    "        positives.append(hard_pos)\n",
    "        negatives.append(hard_neg)\n",
    "    return anchors, positives, negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = pd.DataFrame(columns=['anchor','positive','negative'])\n",
    "triplets.anchor, triplets.positive, triplets.negative = compute_triplets(2048)\n",
    "# triplets.to_csv('./data/triplets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [ np.array([preprocess_input(cv2.imread(im)) for im in triplets.anchor]),\n",
    "           np.array([preprocess_input(cv2.imread(im)) for im in triplets.positive]),\n",
    "           np.array([preprocess_input(cv2.imread(im)) for im in triplets.negative])]\n",
    "y_train = np.empty(len(triplets), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load previously coarsly pre-trained model and train continue training on hard triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/anaconda3/envs/cv-course-env/lib/python3.5/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "trained_model = load_model(filepath='./model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_triplet_model(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y=y_train, batch_size=512, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean distance\n",
    "def distance(vec1,vec2):\n",
    "    return np.sqrt(np.sum(np.square(vec1-vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top five predictions\n",
    "def top_five(img):\n",
    "    ftrs = trained_model.predict(img[None,...])[0]\n",
    "    return sorted([(distance(cls_repr[Id],ftrs),Id) for Id in unique_ids])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth:\n",
      "w_f48451c\n",
      "Top five predictions:\n",
      "(16.185738940751019, 'w_f48451c')\n",
      "(16.548555263056986, 'w_8d76b75')\n",
      "(17.247622089332403, 'w_1baf8df')\n",
      "(17.456435307224197, 'w_0d4a14b')\n",
      "(17.609687916312609, 'w_9438119')\n"
     ]
    }
   ],
   "source": [
    "# demo single image identification\n",
    "preds = top_five(preprocess_input(cv2.imread(labels.Image[0])))\n",
    "print('Truth:',labels.Id[0],'Top five predictions:',*preds, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_five(num_samples):\n",
    "    map5 = 0.0\n",
    "    for lbl in labels.sample(n=num_samples).itertuples():\n",
    "        preds = top_five(preprocess_input(cv2.imread(lbl.Image)))\n",
    "        map5 += sum([(p[1]==lbl.Id)/i for i,p in zip(range(1,6),preds)])\n",
    "    return map5/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean average pericion of top five predictions per each sample:\n",
      "0.46875\n"
     ]
    }
   ],
   "source": [
    "print('Mean average pericion of top five predictions per each sample:')\n",
    "print(map_five(num_samples=64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv-course-env]",
   "language": "python",
   "name": "conda-env-cv-course-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
